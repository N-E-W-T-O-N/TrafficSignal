{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1be19",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "from skimage import io\n",
    "\n",
    "import numpy as np\n",
    "#import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f424a7",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as TK\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense\n",
    "from tensorflow.keras.layers import BatchNormalization,Flatten,Dropout\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017bbade",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1c8bd",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "class Traffic:\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,classes) :\n",
    "        \n",
    "        model = Sequential() # model is developed in sequential way\n",
    "        chanDim = -1\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        #conv=>Relu=>BN=>Pool\n",
    "        model.add(Conv2D(8,(5,5),padding='same',input_shape=inputShape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(16,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        \n",
    "        model.add(Conv2D(16,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(32,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5)) #regularization use to  penalize overfitting\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5)) \n",
    "        #Since numer of class is greater than 2 we are using softmax activation function\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4004e65",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "def load_split(basePath,csvPath):\n",
    "    data=[]\n",
    "    labels = []\n",
    "    rows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
    "    random.shuffle(rows)\n",
    "    for (i, row) in enumerate(rows):\n",
    "        # check to see if we should show a status update\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {} total images\".format(i))\n",
    "        # split the row into components and then grab the class ID\n",
    "     # and image path\n",
    "        (label, imagePath) = row.strip().split(\",\")[-2:]\n",
    "    # derive the full path to the image file and load it\n",
    "        imagePath = os.path.sep.join([basePath, imagePath])\n",
    "        image = io.imread(imagePath)\n",
    "\n",
    "        image = transform.resize(image, (32, 32))\n",
    "        image = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
    "        # update the list of data and labels, respectively\n",
    "        data.append(image)\n",
    "        labels.append(int(label))\n",
    "    # convert the data and labels to NumPy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    print(\"You are using {} images\".format(len(labels)))\n",
    "    # return a tuple of the data and labels\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8e95d",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "basePath = \"Data\"\n",
    "\n",
    "\n",
    "trainPath = os.path.sep.join([basePath, \"Train.csv\"])\n",
    "testPath = os.path.sep.join([basePath, \"Test.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc5922",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "# load the label names\n",
    "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
    "print(labelNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372668e",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading training data...\")\n",
    "(train_x, train_y) = load_split(basePath, trainPath)\n",
    "print(\"\\n[INFO] loading testing data...\")\n",
    "(test_x, test_y) = load_split(basePath, testPath)\n",
    "# scale data to the range of [0, 1]\n",
    "train_x = train_x.astype(\"float32\") / 255.0\n",
    "test_x = test_x.astype(\"float32\") / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f0507",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "print(np.unique(train_y))\n",
    "\n",
    "'''\n",
    "# calculate the total number of images in each class and\n",
    "# initialize a dictionary to store the class weights\n",
    "classTotals = trainY.sum(axis=0)\n",
    "classWeight = dict()\n",
    "print(classTotals)\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "\tclassWeight[i] = classTotals.max() / classTotals[i]\n",
    "'''\n",
    "from sklearn.utils import class_weight\n",
    "c_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(train_y),\n",
    "                                                 y=train_y)\n",
    "print(c_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924848fc",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "c_weights = {i:w for i,w in enumerate(c_weights)}\n",
    "c_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15f3ff",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# one-hot encode the training and testing labels\n",
    "numLabels = len(np.unique(train_y))\n",
    "trainY = to_categorical(train_y, numLabels)\n",
    "testY = to_categorical(test_y, numLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28871ed",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(trainY[0])\n",
    "print(train_x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376da59f",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=10,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=False,\n",
    "\tvertical_flip=False,\n",
    "\tfill_mode=\"nearest\")\n",
    "# initialize the optimizer and compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR, weight_decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
    "model = Traffic.build(width=32, height=32, depth=3,classes=numLabels)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "\taug.flow(train_x, trainY, batch_size=BS),\n",
    "\tvalidation_data=(test_x, testY),\n",
    "\tsteps_per_epoch=train_x.shape[0] // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tclass_weight=c_weights,\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901f26c",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(test_x, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=labelNames))\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format(\"Trafiic Signal/Model\"))\n",
    "model.save(\"Trafiic Signal/Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c65632",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, NUM_EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9477e8",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
